######################
Day 8 - 7th Apr. 2024
######################		
				
	Kubernetes ::::
	
		- It is a Open-Source Container Orchestration Tool 
		- Kubernetes is used to Deploy any type of Containers.
		- It is used to ensure high availability of the Applications/services running thru Containers.
		- Used to Ensure High Availability of Containers by creating Replicas of Containers.
		- It supports Auto-Scaling & Load Balancing.
		
	Managed Services :::
	
		- AWS 	- EKS,ECS,ECR 
		- Azure - AKS,ECS,ECR  
		- GCP   - GKE,GCE,GCR  
		
		
	Kubernetes Architecture :::
	
	Kubernetes Architecture Components :::
	
	
	Terminologies 
	
		- Pods
		- Namespaces 
		- kubectl
		- kubeadm 
		- Deployment Controller object 
		- Services 
			- Node-Port 
			- Cluster-IP 
			- Load Balancer 
		- Volumes
			- Hostpath volume 
	
		
		
	Kubernetes Architecture :::
	
	
		Kubernetes_Master 	
			Kubernetes_WorkerNode1
			Kubernetes_WorkerNode2
			Kubernetes_WorkerNode3
	
		Cluster 	- Collection of Worknodes 
	
	Non-Prod									PROD Environment
	
	Dev/Test			====>						Prod_Servers 

												Kubernetes_Master 	
													Kubernetes_WorkerNode1
													Kubernetes_WorkerNode2
													Kubernetes_WorkerNode3	
		Kubernetes_Master
			Kubernetes_Master1 	
				Cluster1
					Kubernetes_WorkerNode1
					Kubernetes_WorkerNode2
					Kubernetes_WorkerNode3	
				Cluster2
					Kubernetes_WorkerNode1
					Kubernetes_WorkerNode2
					Kubernetes_WorkerNode3	
				Cluster3
					Kubernetes_WorkerNode1
					Kubernetes_WorkerNode2
					Kubernetes_WorkerNode3	
			Kubernetes_Master2 	
				Cluster1
					Kubernetes_WorkerNode1
					Kubernetes_WorkerNode2
					Kubernetes_WorkerNode3	
				Cluster2
					Kubernetes_WorkerNode1
					Kubernetes_WorkerNode2
					Kubernetes_WorkerNode3	
				Cluster3
					Kubernetes_WorkerNode1
					Kubernetes_WorkerNode2
					Kubernetes_WorkerNode3	
					
					
		
					
Kubernetes Architecture Components :::	
Kubernetes Architecture::::
	
Architecture ::::

Master Components

Below are the main components on the Kubernetes master node:

etcd cluster – a simple, distributed key value storage which is used to store the Kubernetes cluster data (such as number of pods, their state, namespace, etc), API objects and service discovery details. It is only accessible from the API server for security reasons. 

kube-apiserver – Kubernetes API server is the central management entity that receives all REST requests for modifications (to pods, services, replication sets/controllers and others), serving as frontend to the cluster. 
Also, this is the only component that communicates with the etcd cluster, making sure data is stored in etcd and agrees with the service details of the deployed pods.

kube-controller-manager – runs several distinct controller processes in the background (for example, replication controller controls number of replicas in a pod, endpoints controller populates endpoint objects like services and pods, and others) to regulate the shared state of the cluster and perform routine tasks. 

cloud-controller-manager – is responsible for managing controller processes with dependencies on the underlying cloud provider (if applicable). For example, when a controller needs to check if a node was terminated or set up routes, load balancers or volumes in the cloud infrastructure, all that is handled by the cloud-controller-manager.

kube-scheduler – helps schedule the pods (a co-located group of containers inside which our application processes are running) on the various nodes based on resource utilization. It reads the service’s operational requirements and schedules it on the best fit node. 




Node (worker) components

Below are the main components found on a (worker) node:

kubelet – the main service on a node, regularly taking in new or modified pod specifications (primarily through the kube-apiserver) and ensuring that pods and their containers are healthy and running in the desired state. This component also reports to the master on the health of the host where it is running.

kube-proxy – a proxy service that runs on each worker node to deal with individual host subnetting and expose services to the external world. It performs request forwarding to the correct pods/containers across the various isolated networks in a cluster.


		Install and Configure Kubernetes Cluster:::
		
		https://kubernetes.io/docs/setup/
		
		minikube 
		
		kubeadm
		
												Kubernetes_Master 	
													Kubernetes_WorkerNode1
													Kubernetes_WorkerNode2



		
		
		Install and Configure Kubernetes Cluster:::
		
		
		1. Launch 3 Vms - (1 KM, 2K_WNs)
		2. Setup the Inbound rule to all the required ports
		
		Following commands shd be executed in all the nodes :
		
			3. Setup unique host name
			4. Install Docker
			5. Install CRI - Container-D 
				Pre-requisites & Config 
			6. Start Container-D Service 
			7. Install Kubeadm, kubectl, kubelet 
			8. Swap-off 
			9. Enable kubelet 
			
		Only in Master_Node :
			10. Kubeadm Init  


		Only in WorkNodes :
			11. Kubeadm Join  



	Concepts:
	
		- Pods
		- Namespaces 
		- kubectl
		- kubeadm 
		- Deployment Controller object 
		- Services 
			- Node-Port 
			- Cluster-IP 
			- Load Balancer 
		- Volumes
			- Hostpath volume 


#######################
Day 9 - 13th Apr. 2024
#######################

		- Pods
		- Namespaces 
		- kubectl		# Is a command line utility, to interact with kubernetes
		- kubeadm 
		- Deployment Controller object 
		- Services 
			- Node-Port 
			- Cluster-IP 
			- Load Balancer 
		- Volumes
			- Hostpath volume 

	
	- Deployment Controller object 
	
		- Deploy the pods 
		- Create replicaset to replicate the pods 
		- Upgrade the pods 
		- rollback the upgrade 
		- Scale-Up 
		- Scale-Down
		
		- Deployment Object
		- Replicaset 
		- Relicas of Pods 
		
		
		This is to ensure high availability of applications running in the pods
		
		Deployment Strategy:
		
			Kubernetes Deployment Controller Object, byt default uses:
				Rolling-Update Strategy for deployment of upgrade.
					- It is used to upgrade the pod one after the other.
							
							
				Launch - 10000 users to access their website simultaneously.
				
				1000 instances of pods 
				
				50000 ?
				
				
				
				
		
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-app
spec:
  replicas: 3
  template:
    metadata:
      labels:							# used in the Selector to refer the template
        app: nginx-app
    spec:
      containers:
      - name: nginx-container
        image: nginx:stable-alpine-slim
        ports:
        - containerPort: 80
  selector:								# used by the Deployment Object to refer the template
    matchLabels:
      app: nginx-app



	Replicaset 	-> It is used to run a specific number of pods at any point of time.

	- Services 
		- Node-Port 
		- Cluster-IP 
		- Load Balancer 	
		
	Igress Controller ::	Are introduced to reduce the number of Load Balancer. As Load Balancers are costly entity, we define Load Balancer at the Application Level. NOT at each service Level. 
	
		Simple routing 			- Static Web Page. - www.loksai.blogsite
		
		Host based routing										Path based routing 
		
		
		
			www.google.com											www.gmail.com
		
			https://drive.google.com/								www.gmail.com/inbox							
		
			https://translate.google.com/							www.gmail.com/sent
			
			https://mail.google.com/
			
			

	Cluster-IP Service :::
	
	
	Kubernetes - 
	
		Kubernetes: Developer/Admin/Securityadmin -
		
	Kubernetes Volumes :::
	
		Presistant data
		
		Docker volumes : 
		
		HostPath Volume :
			 - it same as like docker volume 
			 
			 Created a vol in a specific host machine

			 mounted tht volume to the container vol during exec.
			 
			 
			 
		KMaster:			POD - deploy
		
			WN1
			WN2
			WN3
			 
			 
		- Namespaces 	:::
		
		What is Namespace in Kubernetes??
		
			- It is a logical partitioning of Kubernetes Cluster.
			
			Created based on Teams / Environments
			
		Non-Prod:
		
			Kubernetes_Master
				Kubernetes_WorkerNode1,2,3,4,5
				
			Developer - Deploy a pod 
				dev namespace
				qa namespace
				uat namespace


		Prod: 24/7 availability
		
		Kubernetes_Master
			Kubernetes_WorkerNode1,2,3,4,5
			
		Blue Green Deployment Strategy ?
		
		Production Server ::: LIVE 
		
			myweb_app_v1.10 ==> LIVE 						# Active Server		- Down this server
			
			Minor Releases
			
			Major Releases 
			
			Replica of Prod Server ==> 
			
			Deploy the Major Release => mywebapp_v2.0		# Passive Server  --> Convert this as LIVE Server 
			
			
		Prod: 24/7 availability
		
		Kubernetes_Master
			Kubernetes_WorkerNode1,2,3,4,5		
			
			
				Namespace : Active: myweb_app_v1.10 ==> LIVE - delete Ns
				
				Namespace : NextGen-v1: mywebapp_v2.0 ==> LIVE

Next:

	Fundamentals of Prometheus/Grafana 
			
	CICD - Demo
	
	
